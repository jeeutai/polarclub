import pandas as pd
import os
import sys
import importlib
import traceback
from datetime import datetime, timedelta
import json
import re

class AdvancedTestSystem:
    def __init__(self):
        self.test_results = {}
        self.critical_errors = []
        self.warnings = []
        self.deployment_ready = True
        self.test_data = {}
        self.auto_fixes_applied = []

    def run_all_tests(self):
        """Run all tests with auto-fix capabilities"""
        print("ğŸ§ª ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì‹œì‘")
        print("ìë™ ìˆ˜ì • ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n")

        test_sequence = [
            ("í™˜ê²½ ê²€ì‚¬", self.test_environment),
            ("ë¬¸ë²• ê²€ì‚¬", self.test_syntax_all_files),
            ("ëª¨ë“ˆ ì„í¬íŠ¸", self.test_all_imports),
            ("ë°ì´í„° êµ¬ì¡°", self.test_data_structure_integrity),
            ("ì¸ì¦ ì‹œìŠ¤í…œ", self.test_authentication_system),
            ("ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§", self.test_business_logic),
            ("Streamlit ê¸°ëŠ¥", self.test_streamlit_functionality),
            ("ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸", self.test_functional_features),
            ("ë¡œê·¸ ì‹œìŠ¤í…œ", self.test_logging_system),
            ("ë°°í¬ ì¤€ë¹„", self.test_deployment_readiness),
            ("ë³´ì•ˆ ê²€ì‚¬", self.test_security),
            ("ì„±ëŠ¥ ê²€ì‚¬", self.test_performance)
        ]

        for test_name, test_function in test_sequence:
            print(f"\n{'â”€'*60}")
            print(f"ğŸ” {test_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
            print(f"{'â”€'*60}")

            try:
                result = test_function()
                if result:
                    print(f"âœ… {test_name} í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                else:
                    print(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            except Exception as e:
                error_msg = f"{test_name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
                print(f"ğŸš¨ {error_msg}")
                self.critical_errors.append(error_msg)
                self.deployment_ready = False

        # Auto-fix ì‹œë„
        if self.critical_errors or self.warnings:
            print(f"\n{'='*60}")
            print("ğŸ”§ ìë™ ìˆ˜ì • ì‹œë„")
            print(f"{'='*60}")
            self.attempt_auto_fixes()

        # Generate final report
        return self.generate_comprehensive_report()

    def test_environment(self):
        """Test environment setup"""
        print("ğŸŒ í™˜ê²½ ì„¤ì • ê²€ì‚¬...")

        env_results = {}

        # Check Python version
        python_version = sys.version_info
        if python_version >= (3, 8):
            print(f"âœ… Python ë²„ì „: {python_version.major}.{python_version.minor}.{python_version.micro}")
            env_results['python_version'] = "OK"
        else:
            print(f"âš ï¸  Python ë²„ì „ì´ ë‚®ìŠµë‹ˆë‹¤: {python_version.major}.{python_version.minor}")
            env_results['python_version'] = "OLD_VERSION"
            self.warnings.append("Python 3.8 ì´ìƒì„ ê¶Œì¥í•©ë‹ˆë‹¤")

        # Check required directories
        required_dirs = ['data', 'attached_assets']
        for dir_name in required_dirs:
            if os.path.exists(dir_name):
                print(f"âœ… {dir_name} ë””ë ‰í† ë¦¬ ì¡´ì¬")
                env_results[f'{dir_name}_dir'] = "EXISTS"
            else:
                print(f"âš ï¸  {dir_name} ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘...")
                os.makedirs(dir_name)
                env_results[f'{dir_name}_dir'] = "CREATED"

        # Check file permissions
        try:
            test_file = 'test_write_permission.tmp'
            with open(test_file, 'w') as f:
                f.write('test')
            os.remove(test_file)
            print("âœ… íŒŒì¼ ì“°ê¸° ê¶Œí•œ ì •ìƒ")
            env_results['write_permission'] = "OK"
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì“°ê¸° ê¶Œí•œ ì˜¤ë¥˜: {e}")
            env_results['write_permission'] = "ERROR"
            self.critical_errors.append(f"íŒŒì¼ ì“°ê¸° ê¶Œí•œ ì—†ìŒ: {e}")
            self.deployment_ready = False

        self.test_results['environment'] = env_results
        return len([r for r in env_results.values() if 'ERROR' in r]) == 0

    def test_all_imports(self):
        """Test all Python module imports with auto-fix"""
        print("ğŸ” ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        modules_to_test = [
            'auth', 'data_manager', 'ui_components', 'board_system',
            'chat_system', 'assignment_system', 'quiz_system',
            'attendance_system', 'schedule_system', 'report_generator',
            'vote_system', 'gallery_system', 'video_conference_system',
            'backup_system', 'notification_system', 'search_system',
            'admin_system', 'ai_assistant', 'gamification_system',
            'portfolio_system', 'logging_system', 'enhanced_features',
            'additional_features', 'initialize_data'
        ]

        import_results = {}

        for module_name in modules_to_test:
            try:
                # ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œë„
                if module_name in sys.modules:
                    del sys.modules[module_name]  # ìºì‹œ ì œê±°

                module = importlib.import_module(module_name)
                print(f"âœ… {module_name}: ì„í¬íŠ¸ ì„±ê³µ")
                import_results[module_name] = "SUCCESS"
                self.test_data[module_name] = module

            except SyntaxError as e:
                error_msg = f"ë¬¸ë²• ì˜¤ë¥˜: {str(e)}"
                print(f"âŒ {module_name}: {error_msg}")
                import_results[module_name] = f"SYNTAX_ERROR: {error_msg}"
                self.critical_errors.append(f"{module_name}: {error_msg}")
                self.deployment_ready = False

                # ìë™ ìˆ˜ì • ì‹œë„
                if self.auto_fix_syntax_error(module_name, e):
                    self.auto_fixes_applied.append(f"ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •: {module_name}")

            except ImportError as e:
                error_msg = f"ì„í¬íŠ¸ ì˜¤ë¥˜: {str(e)}"
                print(f"âš ï¸  {module_name}: {error_msg}")
                import_results[module_name] = f"IMPORT_ERROR: {error_msg}"
                self.warnings.append(f"{module_name}: {error_msg}")

                # ìë™ ìˆ˜ì • ì‹œë„
                if self.auto_fix_import_error(module_name, e):
                    self.auto_fixes_applied.append(f"ì„í¬íŠ¸ ì˜¤ë¥˜ ìˆ˜ì •: {module_name}")

            except Exception as e:
                error_msg = f"ê¸°íƒ€ ì˜¤ë¥˜: {str(e)}"
                print(f"âŒ {module_name}: {error_msg}")
                import_results[module_name] = f"ERROR: {error_msg}"
                self.critical_errors.append(f"{module_name}: {error_msg}")
                self.deployment_ready = False

        self.test_results['imports'] = import_results
        return len(self.critical_errors) == 0

    def test_syntax_all_files(self):
        """Test syntax of all Python files with auto-fix"""
        print("\nğŸ“ ëª¨ë“  Python íŒŒì¼ ë¬¸ë²• ê²€ì‚¬ ì‹œì‘...")

        python_files = [f for f in os.listdir('.') if f.endswith('.py')]
        syntax_results = {}

        for file_name in python_files:
            try:
                with open(file_name, 'r', encoding='utf-8') as f:
                    content = f.read()

                compile(content, file_name, 'exec')
                print(f"âœ… {file_name}: ë¬¸ë²• ì •ìƒ")
                syntax_results[file_name] = "SYNTAX_OK"

            except SyntaxError as e:
                error_msg = f"ì¤„ {e.lineno}: {e.msg}"
                print(f"âŒ {file_name}: ë¬¸ë²• ì˜¤ë¥˜ - {error_msg}")
                syntax_results[file_name] = f"SYNTAX_ERROR: {error_msg}"
                self.critical_errors.append(f"{file_name}: {error_msg}")
                self.deployment_ready = False

                # ìë™ ìˆ˜ì • ì‹œë„
                if self.auto_fix_file_syntax(file_name, e, content):
                    self.auto_fixes_applied.append(f"íŒŒì¼ ë¬¸ë²• ìˆ˜ì •: {file_name}")

            except Exception as e:
                error_msg = f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"
                print(f"âš ï¸  {file_name}: {error_msg}")
                syntax_results[file_name] = f"READ_ERROR: {error_msg}"
                self.warnings.append(f"{file_name}: {error_msg}")

        self.test_results['syntax'] = syntax_results
        return len([r for r in syntax_results.values() if 'SYNTAX_ERROR' in r]) == 0

    def test_data_structure_integrity(self):
        """Test comprehensive data structure integrity with auto-fix"""
        print("\nğŸ—„ï¸  ë°ì´í„° êµ¬ì¡° ë¬´ê²°ì„± ê²€ì‚¬ ì‹œì‘...")

        data_integrity_results = {}

        # Test data directory
        if not os.path.exists('data'):
            print("âš ï¸  data ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒì„± ì¤‘...")
            os.makedirs('data')
            self.auto_fixes_applied.append("data ë””ë ‰í† ë¦¬ ìƒì„±")

        # Required CSV files and their expected columns
        csv_requirements = {
            'users.csv': ['username', 'password', 'name', 'role', 'club_name', 'club_role', 'created_date'],
            'clubs.csv': ['name', 'icon', 'description', 'president', 'max_members', 'created_date'],
            'posts.csv': ['id', 'title', 'content', 'author', 'club', 'created_date', 'likes', 'comments'],
            'assignments.csv': ['id', 'title', 'description', 'club', 'creator', 'due_date', 'status', 'created_date'],
            'attendance.csv': ['id', 'username', 'club', 'date', 'status', 'recorded_by'],
            'quizzes.csv': ['id', 'title', 'description', 'club', 'creator', 'questions', 'time_limit', 'attempts_allowed', 'status', 'created_date'],
            'schedules.csv': ['id', 'title', 'description', 'club', 'date', 'time', 'location', 'creator', 'created_date'],
            'notifications.csv': ['id', 'username', 'title', 'message', 'type', 'read', 'created_date'],
            'badges.csv': ['id', 'username', 'badge_name', 'badge_icon', 'description', 'awarded_date', 'awarded_by'],
            'votes.csv': ['id', 'title', 'description', 'options', 'club', 'creator', 'end_date', 'created_date'],
            'logs.csv': ['id', 'timestamp', 'username', 'user_name', 'user_role', 'club_name', 'ip_address', 'session_id', 'activity_type', 'activity_description', 'target_resource', 'action_result', 'error_message', 'user_agent', 'device_type', 'browser_info', 'request_method', 'response_time', 'data_modified', 'security_level', 'notes']
        }

        for csv_file, required_columns in csv_requirements.items():
            file_path = f"data/{csv_file}"

            # Check file existence
            if not os.path.exists(file_path):
                print(f"âš ï¸  {csv_file}: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ (ìë™ ìƒì„± ì‹œë„)")
                if self.auto_create_csv_file(csv_file, required_columns):
                    data_integrity_results[csv_file] = "MISSING_CREATED"
                    self.auto_fixes_applied.append(f"CSV íŒŒì¼ ìƒì„±: {csv_file}")
                continue

            try:
                df = pd.read_csv(file_path, encoding='utf-8-sig')

                # Check required columns
                missing_columns = [col for col in required_columns if col not in df.columns]

                if missing_columns:
                    error_msg = f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}"
                    print(f"âŒ {csv_file}: {error_msg}")

                    # ìë™ ìˆ˜ì • ì‹œë„
                    if self.auto_fix_missing_columns(csv_file, missing_columns, df):
                        data_integrity_results[csv_file] = f"FIXED_MISSING_COLUMNS: {missing_columns}"
                        self.auto_fixes_applied.append(f"ëˆ„ë½ ì»¬ëŸ¼ ì¶”ê°€: {csv_file}")
                    else:
                        data_integrity_results[csv_file] = f"MISSING_COLUMNS: {missing_columns}"
                        self.critical_errors.append(f"{csv_file}: {error_msg}")
                        self.deployment_ready = False
                else:
                    print(f"âœ… {csv_file}: êµ¬ì¡° ì •ìƒ ({len(df)}ê°œ ë ˆì½”ë“œ)")
                    data_integrity_results[csv_file] = f"OK: {len(df)} records"

            except Exception as e:
                error_msg = f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}"
                print(f"âŒ {csv_file}: {error_msg}")
                data_integrity_results[csv_file] = f"LOAD_ERROR: {error_msg}"
                self.critical_errors.append(f"{csv_file}: {error_msg}")
                self.deployment_ready = False

        self.test_results['data_integrity'] = data_integrity_results
        return len([r for r in data_integrity_results.values() if 'ERROR' in r or 'MISSING_COLUMNS' in r]) == 0

    def test_authentication_system(self):
        """Test authentication system functionality"""
        try:
            print("ğŸ” ì¸ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

            # Import auth module
            import auth
            auth_manager = auth.AuthManager()

            # Test user loading
            users = auth_manager.load_users()
            if users.empty:
                print("âš ï¸ ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                self.warnings.append("No user data found")
            else:
                print(f"âœ… ì‚¬ìš©ì {len(users)}ëª… ë¡œë“œë¨")

            # Test login functionality
            if 'admin' in users['username'].values:
                print("âœ… ê´€ë¦¬ì ê³„ì • ì¡´ì¬")
            else:
                print("âš ï¸ ê´€ë¦¬ì ê³„ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
                self.warnings.append("No admin account found")

            print("âœ… ì¸ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            return True

        except Exception as e:
            print(f"âŒ ì¸ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.critical_errors.append(f"Authentication test failed: {e}")
            return False

    def test_business_logic(self):
        """Test business logic components"""
        print("\nğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        business_results = {}

        # Test core systems
        core_systems = [
            ('DataManager', 'data_manager'),
            ('AttendanceSystem', 'attendance_system'),
            ('QuizSystem', 'quiz_system'),
            ('NotificationSystem', 'notification_system'),
            ('AdminSystem', 'admin_system'),
            ('BoardSystem', 'board_system'),
            ('ChatSystem', 'chat_system')
        ]

        for class_name, module_name in core_systems:
            try:
                module = importlib.import_module(module_name)
                class_obj = getattr(module, class_name)
                instance = class_obj()
                print(f"âœ… {class_name}: ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
                business_results[class_name] = "INSTANTIATED"
            except Exception as e:
                print(f"âŒ {class_name}: ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ - {e}")
                business_results[class_name] = f"ERROR: {e}"
                self.warnings.append(f"{class_name} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨")

        self.test_results['business_logic'] = business_results
        return len([r for r in business_results.values() if 'ERROR' in r]) == 0

    def test_streamlit_functionality(self):
        """Test Streamlit specific functionality"""
        print("\nğŸ¨ Streamlit ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        streamlit_results = {}

        try:
            import streamlit as st
            print("âœ… Streamlit ì„í¬íŠ¸ ì„±ê³µ")
            streamlit_results['import'] = "SUCCESS"

            # Check app.py structure
            if os.path.exists('app.py'):
                with open('app.py', 'r', encoding='utf-8') as f:
                    app_content = f.read()

                required_functions = ['main()', 'show_login()', 'show_main_app()']
                for func in required_functions:
                    if func in app_content:
                        print(f"âœ… {func} í•¨ìˆ˜ ì¡´ì¬")
                        streamlit_results[func] = "FOUND"
                    else:
                        print(f"âŒ {func} í•¨ìˆ˜ ëˆ„ë½")
                        streamlit_results[func] = "MISSING"
                        self.critical_errors.append(f"í•„ìˆ˜ í•¨ìˆ˜ ëˆ„ë½: {func}")

                # Check for HTML usage (should be minimal)
                html_count = app_content.count('unsafe_allow_html=True')
                if html_count <= 2:
                    print(f"âœ… HTML ì‚¬ìš©ëŸ‰ ì ì ˆ: {html_count}ê°œ")
                    streamlit_results['html_usage'] = f"LOW: {html_count}"
                else:
                    print(f"âš ï¸  HTML ì‚¬ìš©ëŸ‰ ë§ìŒ: {html_count}ê°œ")
                    streamlit_results['html_usage'] = f"HIGH: {html_count}"
                    self.warnings.append(f"HTML ì‚¬ìš©ëŸ‰ ë§ìŒ: {html_count}ê°œ")

            # Check for Streamlit key conflicts
            key_conflicts = self.check_streamlit_key_conflicts()
            if key_conflicts:
                print(f"âŒ Streamlit í‚¤ ì¶©ëŒ ë°œê²¬: {len(key_conflicts)}ê°œ")
                streamlit_results['key_conflicts'] = f"CONFLICTS: {len(key_conflicts)}"
                for conflict in key_conflicts:
                    self.critical_errors.append(f"í‚¤ ì¶©ëŒ: {conflict}")
                    print(f"   - {conflict}")
            else:
                print("âœ… Streamlit í‚¤ ì¶©ëŒ ì—†ìŒ")
                streamlit_results['key_conflicts'] = "NONE"

        except Exception as e:
            print(f"âŒ Streamlit ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            streamlit_results['system'] = f"ERROR: {e}"
            self.critical_errors.append(f"Streamlit ê¸°ëŠ¥ ì˜¤ë¥˜: {e}")

        self.test_results['streamlit_functionality'] = streamlit_results
        return len([r for r in streamlit_results.values() if 'ERROR' in r or 'MISSING' in r or 'CONFLICTS' in r]) == 0

    def test_functional_features(self):
        """Test functional features by actually running them"""
        print("\nâš™ï¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        functional_results = {}

        # Test data manager functionality
        try:
            from data_manager import DataManager
            dm = DataManager()

            # Test loading users
            users_df = dm.load_csv('users')
            if not users_df.empty:
                print(f"âœ… DataManager: ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ ì„±ê³µ ({len(users_df)}ëª…)")
                functional_results['data_manager'] = f"FUNCTIONAL: {len(users_df)} users loaded"
            else:
                print("âš ï¸  DataManager: ì‚¬ìš©ì ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
                functional_results['data_manager'] = "EMPTY_DATA"
                self.warnings.append("ì‚¬ìš©ì ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
        except Exception as e:
            print(f"âŒ DataManager í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            functional_results['data_manager'] = f"ERROR: {e}"
            self.critical_errors.append(f"DataManager ì˜¤ë¥˜: {e}")

        # Test other systems
        systems_to_test = [
            'board_system', 'chat_system', 'assignment_system',
            'quiz_system', 'attendance_system', 'notification_system',
            'admin_system'
        ]

        for system in systems_to_test:
            try:
                module = importlib.import_module(system)
                print(f"âœ… {system}: ì„í¬íŠ¸ ê°€ëŠ¥")
                functional_results[system] = "IMPORTABLE"
            except Exception as e:
                print(f"âŒ {system}: ì„í¬íŠ¸ ì‹¤íŒ¨ - {e}")
                functional_results[system] = f"IMPORT_ERROR: {e}"
                self.warnings.append(f"{system} ì„í¬íŠ¸ ì‹¤íŒ¨")

        self.test_results['functional_features'] = functional_results
        return len([r for r in functional_results.values() if 'ERROR' in r]) <= 2

    def test_logging_system(self):
        """Test logging system functionality"""
        print("\nğŸ“Š ë¡œê·¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        log_results = {}

        try:
            # LoggingSystem ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
            from logging_system import LoggingSystem
            logging_system = LoggingSystem()
            print("âœ… LoggingSystem ì„í¬íŠ¸ ì„±ê³µ")
            log_results['import'] = "SUCCESS"

            # ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            logs_file = 'data/logs.csv'
            if os.path.exists(logs_file):
                logs_df = pd.read_csv(logs_file, encoding='utf-8-sig')
                required_columns = ['id', 'timestamp', 'username', 'activity_type', 'activity_description']

                missing_cols = [col for col in required_columns if col not in logs_df.columns]
                if missing_cols:
                    print(f"âŒ ë¡œê·¸ íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
                    log_results['structure'] = f"MISSING_COLUMNS: {missing_cols}"
                    self.critical_errors.append(f"ë¡œê·¸ íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: {missing_cols}")
                else:
                    print(f"âœ… ë¡œê·¸ íŒŒì¼ êµ¬ì¡° ì •ìƒ ({len(logs_df)}ê°œ ë¡œê·¸)")
                    log_results['structure'] = "OK"
            else:
                print("âŒ ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                log_results['file_exists'] = "MISSING"
                self.critical_errors.append("ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        except Exception as e:
            print(f"âŒ ë¡œê·¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            log_results['system'] = f"ERROR: {e}"
            self.critical_errors.append(f"ë¡œê·¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            self.deployment_ready = False

        self.test_results['logging'] = log_results
        return len([r for r in log_results.values() if 'ERROR' in r]) == 0

    def test_deployment_readiness(self):
        """Test deployment readiness"""
        print("\nğŸš€ ë°°í¬ ì¤€ë¹„ ìƒíƒœ ê²€ì‚¬ ì‹œì‘...")

        deployment_results = {}

        # Check essential files
        essential_files = ['app.py', 'requirements.txt']
        for file_name in essential_files:
            if os.path.exists(file_name):
                print(f"âœ… {file_name}: ì¡´ì¬")
                deployment_results[file_name] = "EXISTS"
            else:
                print(f"âŒ {file_name}: ëˆ„ë½")
                deployment_results[file_name] = "MISSING"
                self.critical_errors.append(f"í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {file_name}")

        # Check pyproject.toml
        if os.path.exists('pyproject.toml'):
            print("âœ… pyproject.toml: ì¡´ì¬")
            deployment_results['pyproject.toml'] = "EXISTS"

        # Test data directory write permissions
        try:
            test_file = 'data/test_write.tmp'
            with open(test_file, 'w') as f:
                f.write('test')
            os.remove(test_file)
            print("âœ… ë°ì´í„° ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ ì •ìƒ")
            deployment_results['data_write_permission'] = "OK"
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ ì˜¤ë¥˜: {e}")
            deployment_results['data_write_permission'] = f"ERROR: {e}"
            self.critical_errors.append(f"ë°ì´í„° ì“°ê¸° ê¶Œí•œ ì˜¤ë¥˜: {e}")

        # Check for large files that might affect deployment
        large_files = []
        html_usage_files = []

        for root, dirs, files in os.walk('.'):
            # Skip hidden directories, data directory, and attached_assets
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['data', 'attached_assets', '__pycache__']]

            for file in files:
                if not file.startswith('.') and file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    try:
                        size = os.path.getsize(file_path)
                        if size > 500 * 1024:  # 500KB for Python files
                            large_files.append((file_path, size))

                        # Check for HTML usage in Python files
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'unsafe_allow_html=True' in content or '<div style=' in content or '<span style=' in content:
                                html_usage_files.append(file_path)
                    except:
                        pass

        if large_files:
            print(f"âš ï¸ í° íŒŒì¼ë“¤ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤ ({len(large_files)}ê°œ):")
            for file_path, size in large_files[:5]:  # Show first 5
                print(f"   - {file_path}: {size // 1024}KB")
            self.warnings.append(f"í° íŒŒì¼ë“¤ì´ ë°°í¬ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒ: {len(large_files)}ê°œ")

            if len(large_files) > 10:
                self.warnings.append(f"í° íŒŒì¼ë“¤ì´ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {len(large_files)}ê°œ")

        if html_usage_files:
            print(f"âš ï¸ HTML ì‚¬ìš©ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤ ({len(html_usage_files)}ê°œ):")
            for file_path in html_usage_files[:3]:  # Show first 3
                print(f"   - {file_path}")
            self.warnings.append(f"HTML ì‚¬ìš©ëŸ‰ ë§ìŒ: {len(html_usage_files)}ê°œ")

        self.test_results['deployment'] = deployment_results
        return len([r for r in deployment_results.values() if 'ERROR' in r or 'MISSING' in r]) == 0

    def test_security(self):
        """Test security aspects"""
        print("\nğŸ”’ ë³´ì•ˆ ê²€ì‚¬ ì‹œì‘...")

        security_results = {}

        # Check for hardcoded passwords
        security_issues = []
        python_files = [f for f in os.listdir('.') if f.endswith('.py')]

        for file_name in python_files:
            try:
                with open(file_name, 'r', encoding='utf-8') as f:
                    content = f.read()

                # í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸ ê²€ì‚¬ (ë” ê´€ëŒ€í•˜ê²Œ)
                password_patterns = [
                    r'password\s*=\s*["\'][^"\']{8,}["\']',  # 8ì ì´ìƒë§Œ ì²´í¬
                    r'secret_key\s*=\s*["\'][^"\']{8,}["\']'
                ]

                for pattern in password_patterns:
                    matches = re.findall(pattern, content, re.IGNORECASE)
                    if matches:
                        security_issues.append(f"{file_name}: í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸ ë°œê²¬")

            except Exception as e:
                self.warnings.append(f"ë³´ì•ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {file_name} - {e}")

        if security_issues:
            print(f"âš ï¸  ë³´ì•ˆ ì´ìŠˆ ë°œê²¬: {len(security_issues)}ê°œ")
            for issue in security_issues:
                print(f"   - {issue}")
            security_results['hardcoded_passwords'] = f"ISSUES: {len(security_issues)}"
            for issue in security_issues:
                self.warnings.append(issue)
        else:
            print("âœ… ì‹¬ê°í•œ í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸ ì—†ìŒ")
            security_results['hardcoded_passwords'] = "OK"

        self.test_results['security'] = security_results
        return len([r for r in security_results.values() if 'CRITICAL' in r]) == 0

    def test_performance(self):
        """Test performance aspects"""
        print("\nâš¡ ì„±ëŠ¥ ê²€ì‚¬ ì‹œì‘...")

        performance_results = {}

        # Check file sizes
        large_files = []
        for root, dirs, files in os.walk('.'):
            for file in files:
                if file.endswith(('.py', '.csv')):
                    file_path = os.path.join(root, file)
                    try:
                        size = os.path.getsize(file_path)
                        if size > 1024 * 1024:  # 1MB
                            large_files.append((file_path, size))
                    except:
                        continue

        if large_files:
            print(f"âš ï¸  í° íŒŒì¼ ë°œê²¬: {len(large_files)}ê°œ")
            for file_path, size in large_files:
                print(f"   - {file_path}: {size / (1024*1024):.2f}MB")
            performance_results['large_files'] = f"FOUND: {len(large_files)}"
            self.warnings.append(f"í° íŒŒì¼ë“¤ì´ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {len(large_files)}ê°œ")
        else:
            print("âœ… ëª¨ë“  íŒŒì¼ í¬ê¸° ì ì •")
            performance_results['large_files'] = "OK"

        self.test_results['performance'] = performance_results
        return True

    def auto_fix_syntax_error(self, module_name, error):
        """Attempt to automatically fix syntax errors"""
        try:
            file_path = f"{module_name}.py"
            if not os.path.exists(file_path):
                return False

            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content

            # ì¼ë°˜ì ì¸ ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •
            # 1. ëˆ„ë½ëœ ì½œë¡  ì¶”ê°€
            content = re.sub(r'(if|elif|else|for|while|def|class|try|except|finally|with)\s+([^:]+)(?<![:\s])\s*\n', r'\1 \2:\n', content)

            # 2. ëˆ„ë½ëœ ê´„í˜¸ ìˆ˜ì •
            lines = content.split('\n')
            for i, line in enumerate(lines):
                # í•¨ìˆ˜ í˜¸ì¶œì—ì„œ ëˆ„ë½ëœ ê´„í˜¸ í™•ì¸
                if 'def ' in line and '(' in line and ')' not in line:
                    lines[i] = line + ')'

            content = '\n'.join(lines)

            # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ ì €ì¥
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"ğŸ”§ {module_name}: ë¬¸ë²• ì˜¤ë¥˜ ìë™ ìˆ˜ì • ì‹œë„")
                return True

        except Exception as e:
            print(f"âŒ {module_name} ìë™ ìˆ˜ì • ì‹¤íŒ¨: {e}")

        return False

    def auto_fix_import_error(self, module_name, error):
        """Attempt to automatically fix import errors"""
        try:
            # ëˆ„ë½ëœ ëª¨ë“ˆ íŒŒì¼ ìƒì„±
            file_path = f"{module_name}.py"
            if not os.path.exists(file_path):
                # ê¸°ë³¸ í´ë˜ìŠ¤ êµ¬ì¡° ìƒì„±
                class_name = ''.join([word.capitalize() for word in module_name.split('_')])

                template = f'''import streamlit as st
import pandas as pd
from datetime import datetime

class {class_name}:
    def __init__(self):
        pass

    def show_interface(self, user):
        """Display the interface"""
        st.markdown("### {class_name}")
        st.info("ì´ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤.")
'''

                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(template)

                print(f"ğŸ”§ {module_name}: ëˆ„ë½ëœ ëª¨ë“ˆ íŒŒì¼ ìë™ ìƒì„±")
                return True

        except Exception as e:
            print(f"âŒ {module_name} ì„í¬íŠ¸ ì˜¤ë¥˜ ìë™ ìˆ˜ì • ì‹¤íŒ¨: {e}")

        return False

    def auto_fix_file_syntax(self, file_name, error, content):
        """Attempt to fix file syntax errors"""
        try:
            # ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •
            if "indentation" in str(error).lower():
                lines = content.split('\n')
                fixed_lines = []

                for line in lines:
                    # íƒ­ì„ ìŠ¤í˜ì´ìŠ¤ë¡œ ë³€í™˜
                    line = line.replace('\t', '    ')
                    fixed_lines.append(line)

                fixed_content = '\n'.join(fixed_lines)

                if fixed_content != content:
                    with open(file_name, 'w', encoding='utf-8') as f:
                        f.write(fixed_content)
                    print(f"ğŸ”§ {file_name}: ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜ ìë™ ìˆ˜ì •")
                    return True

        except Exception as e:
            print(f"âŒ {file_name} ë¬¸ë²• ì˜¤ë¥˜ ìë™ ìˆ˜ì • ì‹¤íŒ¨: {e}")

        return False

    def auto_create_csv_file(self, csv_file, required_columns):
        """Automatically create missing CSV files"""
        try:
            file_path = f"data/{csv_file}"

            # Add sample data for logs.csv
            if csv_file == 'logs.csv':
                sample_data = [{
                    'id': 1,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
                    'username': 'system',
                    'user_name': 'System',
                    'user_role': 'System',
                    'club_name': 'System',
                    'ip_address': '127.0.0.1',
                    'session_id': 'system_init',
                    'activity_type': 'System',
                    'activity_description': 'Log system initialized',
                    'target_resource': 'logs.csv',
                    'action_result': 'Success',
                    'error_message': 'None',
                    'user_agent': 'System',
                    'device_type': 'Server',
                    'browser_info': 'N/A',
                    'request_method': 'INIT',
                    'response_time': '0ms',
                    'data_modified': '1 record',
                    'security_level': 'Normal',
                    'notes': 'System initialization'
                }]
                df = pd.DataFrame(sample_data)
            else:
                df = pd.DataFrame(columns=required_columns)

            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ”§ {csv_file}: ëˆ„ë½ëœ CSV íŒŒì¼ ìë™ ìƒì„±")
            return True
        except Exception as e:
            print(f"âŒ {csv_file} ìë™ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def auto_fix_missing_columns(self, csv_file, missing_columns, df):
        """Automatically add missing columns to CSV files"""
        try:
            file_path = f"data/{csv_file}"

            # ëˆ„ë½ëœ ì»¬ëŸ¼ì„ ì ì ˆí•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€
            for col in missing_columns:
                if col in ['id']:
                    df[col] = range(1, len(df) + 1)
                elif col in ['timestamp', 'created_date', 'awarded_date']:
                    df[col] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                elif col in ['read']:
                    df[col] = False
                elif col in ['likes', 'comments', 'max_members', 'time_limit', 'attempts_allowed']:
                    df[col] = 0
                else:
                    df[col] = ""

            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ”§ {csv_file}: ëˆ„ë½ëœ ì»¬ëŸ¼ ìë™ ì¶”ê°€ - {missing_columns}")
            return True
        except Exception as e:
            print(f"âŒ {csv_file} ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False

    def attempt_auto_fixes(self):
        """Attempt to automatically fix detected issues"""
        print("ğŸ”§ ìë™ ìˆ˜ì • ê¸°ëŠ¥ ì‹¤í–‰ ì¤‘...")

        if not self.auto_fixes_applied:
            print("ğŸ“‹ ìë™ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"âœ… {len(self.auto_fixes_applied)}ê°œì˜ ìë™ ìˆ˜ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for fix in self.auto_fixes_applied:
            print(f"   - {fix}")

        # ìˆ˜ì • í›„ ì¬í…ŒìŠ¤íŠ¸ ì œì•ˆ
        print("\nğŸ”„ ìë™ ìˆ˜ì • í›„ ì¬í…ŒìŠ¤íŠ¸ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

    def generate_comprehensive_report(self):
        """Generate comprehensive test report with auto-fix information"""
        print("\n" + "="*80)
        print("ğŸ“‹ ì¢…í•© í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ (ìë™ ìˆ˜ì • í¬í•¨)")
        print("="*80)

        # Summary
        total_tests = len(self.test_results)
        passed_tests = sum(1 for test_name in self.test_results.keys() 
                          if not any('ERROR' in str(result) for result in self.test_results[test_name].values()))

        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½:")
        print(f"   ì „ì²´ í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬: {total_tests}")
        print(f"   í†µê³¼: {passed_tests}")
        print(f"   ì‹¤íŒ¨: {total_tests - passed_tests}")
        print(f"   ì‹¬ê°í•œ ì˜¤ë¥˜: {len(self.critical_errors)}")
        print(f"   ê²½ê³ : {len(self.warnings)}")
        print(f"   ìë™ ìˆ˜ì • ì ìš©: {len(self.auto_fixes_applied)}")

        # Auto-fix summary
        if self.auto_fixes_applied:
            print(f"\nğŸ”§ ìë™ ìˆ˜ì • ë‚´ì—­:")
            for i, fix in enumerate(self.auto_fixes_applied, 1):
                print(f"   {i}. {fix}")

        # Deployment status
        deployment_status = "âœ… ê°€ëŠ¥" if self.deployment_ready and len(self.critical_errors) == 0 else "âŒ ë¶ˆê°€ëŠ¥"
        print(f"\nğŸš€ ë°°í¬ ê°€ëŠ¥ ì—¬ë¶€: {deployment_status}")

        # Critical errors
        if self.critical_errors:
            print(f"\nğŸš¨ ì‹¬ê°í•œ ì˜¤ë¥˜ ({len(self.critical_errors)}ê°œ):")
            for i, error in enumerate(self.critical_errors, 1):
                print(f"   {i}. {error}")

        # Warnings
        if self.warnings:
            print(f"\nâš ï¸  ê²½ê³  ì‚¬í•­ ({len(self.warnings)}ê°œ):")
            for i, warning in enumerate(self.warnings, 1):
                print(f"   {i}. {warning}")

        # Save detailed report
        self.save_detailed_report()

        print("\n" + "="*80)
        print("ğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        if len(self.critical_errors) == 0:
            print("ğŸš€ ì‹œìŠ¤í…œì´ ë°°í¬ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âš ï¸  ë°°í¬ ì „ ì‹¬ê°í•œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")

        return {
            'deployment_ready': self.deployment_ready and len(self.critical_errors) == 0,
            'critical_errors': len(self.critical_errors),
            'warnings': len(self.warnings),
            'auto_fixes_applied': len(self.auto_fixes_applied),
            'passed_tests': passed_tests,
            'total_tests': total_tests
        }

    def save_detailed_report(self):
        """Save detailed test report to file"""
        try:
            report_data = {
                'timestamp': datetime.now().isoformat(),
                'deployment_ready': self.deployment_ready and len(self.critical_errors) == 0,
                'test_results': self.test_results,
                'critical_errors': self.critical_errors,
                'warnings': self.warnings,
                'auto_fixes_applied': self.auto_fixes_applied,
                'summary': {
                    'total_tests': len(self.test_results),
                    'critical_errors_count': len(self.critical_errors),
                    'warnings_count': len(self.warnings),
                    'auto_fixes_count': len(self.auto_fixes_applied)
                }
            }

            with open('comprehensive_test_report.json', 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)

            print("ğŸ“ ìƒì„¸ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œê°€ comprehensive_test_report.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"âš ï¸  í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def auto_fix_issues(self):
        """Automatically fix detected issues"""
        print("ğŸ”§ ìë™ ìˆ˜ì • ì‹œì‘...")

        fixes_applied = 0

        # Fix missing CSV files
        csv_files = ['users.csv', 'logs.csv', 'attendance.csv', 'assignments.csv', 
                    'submissions.csv', 'posts.csv', 'notifications.csv', 'clubs.csv']

        for csv_file in csv_files:
            if not os.path.exists(f"data/{csv_file}"):
                if self.create_missing_csv(csv_file):
                    fixes_applied += 1

        # Fix missing columns in existing CSV files
        for csv_file in csv_files:
            if os.path.exists(f"data/{csv_file}"):
                df = pd.read_csv(f"data/{csv_file}")
                required_columns = self.get_required_columns(csv_file)
                missing_columns = [col for col in required_columns if col not in df.columns]

                if missing_columns:
                    if self.auto_fix_missing_columns(csv_file, missing_columns, df):
                        fixes_applied += 1

        print(f"ğŸ”§ ìë™ ìˆ˜ì • ì™„ë£Œ: {fixes_applied}ê°œ í•­ëª© ìˆ˜ì •ë¨")
        return fixes_applied > 0

    def create_missing_csv(self, csv_file):
        """Create missing CSV file with required columns"""
        try:
            file_path = f"data/{csv_file}"
            required_columns = self.get_required_columns(csv_file)
            df = pd.DataFrame(columns=required_columns)
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ”§ {csv_file} ìƒì„±ë¨")
            return True
        except Exception as e:
            print(f"âŒ {csv_file} ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def check_streamlit_key_conflicts(self):
        """Check for potential Streamlit key conflicts in Python files"""
        conflicts = []
        python_files = [f for f in os.listdir('.') if f.endswith('.py')]

        for file_name in python_files:
            try:
                with open(file_name, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Find all key= patterns
                key_patterns = re.findall(r'key=f?"([^"]+)"', content)
                key_patterns.extend(re.findall(r"key=f?'([^']+)'", content))

                # Check for potential conflicts (simple static keys without variables)
                static_keys = []
                for key in key_patterns:
                    # Skip f-strings and keys with variables
                    if '{' not in key and not any(var in key for var in ['_', 'id', 'username', 'post']):
                        static_keys.append(key)

                # Find duplicates
                from collections import Counter
                key_counts = Counter(static_keys)
                for key, count in key_counts.items():
                    if count > 1:
                        conflicts.append(f"{file_name}: '{key}' appears {count} times")

                # Check for common problematic patterns
                problematic_patterns = [
                    r'key=f?"delete_\d+"',
                    r'key=f?"edit_\d+"',
                    r'key=f?"like_\d+"',
                    r'key=f?"comment_\d+"'
                ]

                for pattern in problematic_patterns:
                    matches = re.findall(pattern, content)
                    if len(matches) > 1:
                        conflicts.append(f"{file_name}: ì ì¬ì  í‚¤ ì¶©ëŒ íŒ¨í„´ '{pattern}'")

            except Exception as e:
                continue

        return conflicts

    def get_required_columns(self, csv_file):
        """Get required columns for a specific CSV file"""
        if csv_file == 'users.csv':
            return ['username', 'password', 'name', 'role', 'club_name', 'club_role', 'created_date']
        elif csv_file == 'logs.csv':
            return ['id', 'timestamp', 'username', 'user_name', 'user_role', 'club_name', 'ip_address', 'session_id', 'activity_type', 'activity_description', 'target_resource', 'action_result', 'error_message', 'user_agent', 'device_type', 'browser_info', 'request_method', 'response_time', 'data_modified', 'security_level', 'notes']
        elif csv_file == 'attendance.csv':
            return ['id', 'username', 'club', 'date', 'status', 'recorded_by']
        elif csv_file == 'assignments.csv':
            return ['id', 'title', 'description', 'club', 'creator', 'due_date', 'status', 'created_date']
        elif csv_file == 'submissions.csv':
            return ['id', 'assignment_id', 'username', 'submission_date', 'grade', 'feedback']
        elif csv_file == 'posts.csv':
            return ['id', 'title', 'content', 'author', 'club', 'created_date', 'likes', 'comments']
        elif csv_file == 'notifications.csv':
            return ['id', 'username', 'title', 'message', 'type', 'read', 'created_date']
        elif csv_file == 'clubs.csv':
            return ['name', 'icon', 'description', 'president', 'max_members', 'created_date']
        else:
            return []

def comprehensive_system_test():
    """Run comprehensive system tests"""
    print("ğŸ§ª Starting comprehensive system test...")

    results = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'tests': [],
        'summary': {'passed': 0, 'failed': 0, 'warnings': 0}
    }

def test_datetime_formats():
    """Test datetime format consistency"""
    try:
        data_dir = 'data'
        datetime_issues = []

        if os.path.exists(data_dir):
            for filename in os.listdir(data_dir):
                if filename.endswith('.csv'):
                    filepath = os.path.join(data_dir, filename)
                    try:
                        df = pd.read_csv(filepath, encoding='utf-8-sig')

                        # Check datetime columns
                        datetime_columns = ['created_date', 'timestamp', 'submitted_date', 
                                          'awarded_date', 'due_date', 'end_date']

                        for col in datetime_columns:
                            if col in df.columns and not df[col].empty:
                                # Check for inconsistent datetime formats
                                for idx, value in df[col].dropna().iterrows():
                                    if pd.isna(value) or (isinstance(value, str) and value == ''):
                                        continue

                                    # Try to parse with common formats
                                    formats = ['%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S']
                                    parsed = False
                                    for fmt in formats:
                                        try:
                                            datetime.strptime(str(value), fmt)
                                            parsed = True
                                            break
                                        except ValueError:
                                            continue

                                    if not parsed:
                                        datetime_issues.append(f"{filename}:{col} - Invalid format: {value}")

                    except Exception as e:
                        datetime_issues.append(f"{filename} - Error reading file: {e}")

        return {
            'test_name': 'DateTime Format Test',
            'status': 'PASSED' if not datetime_issues else 'FAILED',
            'details': datetime_issues if datetime_issues else ['All datetime formats are valid']
        }

    except Exception as e:
        return {
            'test_name': 'DateTime Format Test',
            'status': 'FAILED',
            'details': [f'Test failed: {e}']
        }

def test_duplicate_keys():
    """Test for potential duplicate Streamlit keys"""
    try:
        issues = []
        python_files = []

        # Find all Python files
        for root, dirs, files in os.walk('.'):
            if 'data' in root or '.git' in root:
                continue
            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))

        # Check for potential duplicate key patterns
        key_patterns = [
            r'key\s*=\s*["\']delete_(\d+)["\']',  # delete_id pattern
            r'key\s*=\s*["\']edit_(\d+)["\']',    # edit_id pattern
            r'key\s*=\s*["\']submit_(\d+)["\']',  # submit_id pattern
        ]

        for filepath in python_files:
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()

                for pattern in key_patterns:
                    matches = re.findall(pattern, content)
                    if len(matches) > len(set(matches)):  # Duplicate IDs found
                        issues.append(f"{filepath}: Potential duplicate key pattern {pattern}")

            except Exception as e:
                issues.append(f"{filepath}: Error reading file: {e}")

        return {
            'test_name': 'Duplicate Keys Test',
            'status': 'PASSED' if not issues else 'WARNING',
            'details': issues if issues else ['No duplicate key patterns detected']
        }

    except Exception as e:
        return {
            'test_name': 'Duplicate Keys Test',
            'status': 'FAILED',
            'details': [f'Test failed: {e}']
        }
# Run tests
    test_functions = [
        test_imports,
        test_data_integrity,
        test_csv_structure,
        test_system_components,
        test_datetime_formats,
        test_duplicate_keys
    ]

if __name__ == "__main__":
    test_system = AdvancedTestSystem()
    results = test_system.run_all_tests()

    # Exit with error code if tests failed
    exit_code = 0 if results['deployment_ready'] else 1
    exit(exit_code)